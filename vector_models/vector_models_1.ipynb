{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторные модели. Word2Vec\n",
    "\n",
    "Мы уже работали с грамматикой — в автоматическом кодировании грамматических категорий, кажется, ничего сверхъестественного нет. Но можно ли как-то закодировать значение слова? Да! В этом нам поможет лингвистическая теория, которая называется дистрибутивной гипотезой. Она утверждает, что значение слова определяется его контекстом — иначе говоря, словами, которые встречаются рядом с этим словом в тексте. Область лингвистики, которая занимается вычислением степени семантической близости между словами/текстами и т.п. на основании их распределения (дистрибуции) в больших массивах данных (текстовых корпусах) назвается **дистрибутивной семантикой**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кратко о существующих системах\n",
    "\n",
    "**GloVe**\n",
    "\n",
    "GloVe берет и строит полную матрицу совместной встречаемости и после этого с помощью алгоритомв уменьшения размерности преобразует ее так, чтобы вектора были опредленной длины\n",
    "\n",
    "\n",
    "**Word2Vec**\n",
    "\n",
    "Это уже нейросеть и она на основе корпуса постепенно подбирает коэффициенты (значения в векторах) для каждого слова так, чтобы с помощью них можно было наилучшим образом предсказывать слова по контексту\n",
    "\n",
    "**FastText**\n",
    "\n",
    "Если мы берем конкретные слова, мы не можем ничего сказать о тех, что нам не встретились (например, уже видели вагон и строитель, а вот вагоностроителя у нас не было). Если мы возьмем слова не целиком, а в виде будквенных нграмм, то мы сможем сложить неизвестные слова.\n",
    "\n",
    "**AdaGram**\n",
    "\n",
    "Все предыдущие модели основаны на графических оболочках и не учитывают многозначность и омонимию. Есть только один вектор для слова \"ключ\" и мы ничего с этим не можем сделать. AdaGram исходит из предположения, что у слова есть n вариантов и если они действительно отличаются и достаточно часто встречаются, он умеет их разделить.\n",
    "\n",
    "**BERT и ELMo**\n",
    "\n",
    "Эти модели не просто могут отличить значения слов, о и скорректировать их вектора в зависимости от контекста, например, понять, что в отрывках “чистый ключ в лесной чаще” и “ключ от квартиры” совсем разные “ключи”. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из самых известных моделей для работы с дистрибутивной семантикой является word2vec. Технология основана на нейронной сети, предсказывающей вероятность встретить слово в заданном контексте. Этот инструмент был разработан группой исследователей Google в 2013 году, руководителем проекта был Томаш Миколов (сейчас работает в Facebook). Вот две самые главные статьи:\n",
    "\n",
    "+ [Efficient Estimation of Word Representations inVector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "+ [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)\n",
    "\n",
    "Полученные таким образом вектора называются распределенными представлениями слов, или **эмбеддингами**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как это обучается?\n",
    "\n",
    "Мы задаём вектор для каждого слова с помощью матрицы $w$ и вектор контекста с помощью матрицы $W$. По сути, word2vec является обобщающим названием для двух архитектур Skip-Gram и Continuous Bag-Of-Words (CBOW).\n",
    "\n",
    "+ **CBOW** предсказывает текущее слово, исходя из окружающего его контекста.\n",
    "\n",
    "+ **Skip-gram**, наоборот, использует текущее слово, чтобы предугадывать окружающие его слова.\n",
    "\n",
    "#### Как это работает?\n",
    "\n",
    "Word2vec принимает большой текстовый корпус в качестве входных данных и сопоставляет каждому слову вектор, выдавая координаты слов на выходе. Сначала он создает словарь, «обучаясь» на входных текстовых данных, а затем вычисляет векторное представление слов. Векторное представление основывается на контекстной близости: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, согласно дистрибутивной гипотезе, имеющие схожий смысл), в векторном представлении будут иметь близкие координаты векторов-слов. Для вычисления близости слов используется косинусное расстояние между их векторами.\n",
    "\n",
    "С помощью дистрибутивных векторных моделей можно строить семантические пропорции (они же аналогии) и решать примеры:\n",
    "\n",
    "+ король: мужчина = королева: женщина $\\Rightarrow$\n",
    "+ король - мужчина + женщина = королева\n",
    "\n",
    "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)\n",
    "\n",
    "Ещё про механику с картинками [тут](https://habr.com/ru/post/446530/)\n",
    "\n",
    "#### Зачем это нужно?\n",
    "\n",
    "+ используется для решения семантических задач\n",
    "+ давайте подумаем, для описания каких семантических классов слов дистрибутивная информация особенно важна?\n",
    "+ несколько интересных статей по дистрибутивной семантике:\n",
    "\n",
    "* [Turney and Pantel 2010](https://jair.org/index.php/jair/article/view/10640)\n",
    "* [Lenci 2018](https://www.annualreviews.org/doi/abs/10.1146/annurev-linguistics-030514-125254?journalCode=linguistics)\n",
    "* [Smith 2019](https://arxiv.org/pdf/1902.06006.pdf)\n",
    "* [Pennington et al. 2014](https://www.aclweb.org/anthology/D14-1162/)\n",
    "* [Faruqui et al. 2015](https://www.aclweb.org/anthology/N15-1184/)\n",
    "\n",
    "+ подаётся на вход нейронным сетям\n",
    "+ используется в Siri, Google Assistant, Alexa, Google Translate...\n",
    "\n",
    "#### Gensim\n",
    "\n",
    "Использовать предобученную модель эмбеддингов или обучить свою можно с помощью библиотеки `gensim`. Вот ее [документация](https://radimrehurek.com/gensim/models/word2vec.html). Вообще-то `gensim` — библиотека для тематического моделирования текстов, но один из компонентов в ней — реализация на python алгоритмов из библиотеки word2vec (которая в оригинале была написана на C++).\n",
    "\n",
    "Если gensim у вас не стоит, то ставим: `pip install gensim`. Можно сделать это прямо из jupyter'а! Чтобы выполнить какую-то команду не в питоне, в командной строке, нужно написать перед ней восклицательный знак.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как обучить свою модель\n",
    "\n",
    "NB! Обратите внимание, что тренировка модели не включает препроцессинг! Это значит, что избавляться от пунктуации, приводить слова к нижнему регистру, лемматизировать их, проставлять частеречные теги придется до тренировки модели (если, конечно, это необходимо для вашей задачи). Т.е. в каком виде слова будут в исходном тексте, в таком они будут и в модели.\n",
    "\n",
    "Поскольку иногда тренировка модели занимает много времени, то можно ещё вести лог событий, чтобы понимать, что на каком этапе происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход модели даем текстовый файл, каждое предложение на отдельной строчке. Вот игрушечный пример с текстом «Бедной Лизы». Он заранее очищен от пунктуации, приведен к нижнему регистру и лемматизирован."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'liza_lem.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель. Основные параметры:\n",
    "\n",
    "+ данные должны быть итерируемым объектом\n",
    "+ size — размер вектора,\n",
    "+ window — размер окна наблюдения,\n",
    "+ min_count — мин. частотность слова в корпусе,\n",
    "+ sg — используемый алгоритм обучения (0 — CBOW, 1 — Skip-gram),\n",
    "+ sample — порог для downsampling'a высокочастотных слов,\n",
    "+ workers — количество потоков,\n",
    "+ alpha — learning rate,\n",
    "+ iter — количество итераций,\n",
    "+ max_vocab_size — позволяет выставить ограничение по памяти при создании словаря (т.е. если ограничение привышается, то низкочастотные слова будут выбрасываться). Для сравнения: 10 млн слов = 1Гб RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 13:55:35,204 : INFO : collecting all words and their counts\n",
      "2019-10-17 13:55:35,206 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-10-17 13:55:35,209 : INFO : collected 1213 word types from a corpus of 3109 raw words and 392 sentences\n",
      "2019-10-17 13:55:35,210 : INFO : Loading a fresh vocabulary\n",
      "2019-10-17 13:55:35,212 : INFO : effective_min_count=2 retains 478 unique words (39% of original 1213, drops 735)\n",
      "2019-10-17 13:55:35,213 : INFO : effective_min_count=2 leaves 2374 word corpus (76% of original 3109, drops 735)\n",
      "2019-10-17 13:55:35,216 : INFO : deleting the raw counts dictionary of 1213 items\n",
      "2019-10-17 13:55:35,217 : INFO : sample=0.001 downsamples 83 most-common words\n",
      "2019-10-17 13:55:35,218 : INFO : downsampling leaves estimated 1817 word corpus (76.6% of prior 2374)\n",
      "2019-10-17 13:55:35,220 : INFO : estimated required memory for 478 words and 300 dimensions: 1386200 bytes\n",
      "2019-10-17 13:55:35,220 : INFO : resetting layer weights\n",
      "2019-10-17 13:55:35,231 : INFO : training model with 3 workers on 478 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-10-17 13:55:35,240 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,243 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,244 : INFO : EPOCH - 1 : training on 3109 raw words (1778 effective words) took 0.0s, 258736 effective words/s\n",
      "2019-10-17 13:55:35,251 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,251 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,256 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,257 : INFO : EPOCH - 2 : training on 3109 raw words (1828 effective words) took 0.0s, 184452 effective words/s\n",
      "2019-10-17 13:55:35,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,262 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,268 : INFO : EPOCH - 3 : training on 3109 raw words (1794 effective words) took 0.0s, 199715 effective words/s\n",
      "2019-10-17 13:55:35,273 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,277 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,278 : INFO : EPOCH - 4 : training on 3109 raw words (1808 effective words) took 0.0s, 255070 effective words/s\n",
      "2019-10-17 13:55:35,334 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-17 13:55:35,335 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-17 13:55:35,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-17 13:55:35,339 : INFO : EPOCH - 5 : training on 3109 raw words (1828 effective words) took 0.1s, 31286 effective words/s\n",
      "2019-10-17 13:55:35,340 : INFO : training on a 15545 raw words (9036 effective words) took 0.1s, 83990 effective words/s\n",
      "2019-10-17 13:55:35,340 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 ms, sys: 9.63 ms, total: 158 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%time model_liza = gensim.models.Word2Vec(data, size=300, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно нормализовать вектора, тогда модель будет занимать меньше RAM. Однако после этого её нельзя дотренировывать. Здесь используется L2-нормализация: вектора нормализуются так, что если сложить квадраты всех элементов вектора, в сумме получится 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 13:55:45,348 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-10-17 13:55:45,356 : INFO : storing 478x300 projection weights into liza.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_liza.init_sims(replace=True)\n",
    "model_path = \"liza.bin\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_liza.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим, сколько в модели слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478\n"
     ]
    }
   ],
   "source": [
    "print(len(model_liza.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['анюта', 'армия', 'ах', 'барин', 'бедный', 'белый', 'берег', 'березовый', 'беречь', 'бесчисленный', 'благодарить', 'бледный', 'блеснуть', 'блестящий', 'близ', 'бог', 'богатый', 'большой', 'бояться', 'брать', 'бросать', 'бросаться', 'бывать', 'быть', 'важный', 'ввечеру', 'вдова', 'велеть', 'великий', 'великолепный', 'верить', 'верно', 'весело', 'веселый', 'весна', 'вести', 'весь', 'весьма', 'ветвь', 'ветер', 'вечер', 'взглядывать', 'вздох', 'вздыхать', 'взор', 'взять', 'вид', 'видеть', 'видеться', 'видный', 'вместе', 'вода', 'возвращаться', 'воздух', 'война', 'воображать', 'воображение', 'воспоминание', 'восторг', 'восхищаться', 'время', 'все', 'вслед', 'вставать', 'встречаться', 'всякий', 'высокий', 'выть', 'выходить', 'глаз', 'глубокий', 'гнать', 'говорить', 'год', 'голос', 'гора', 'горе', 'горестный', 'горлица', 'город', 'горький', 'господь', 'гром', 'грусть', 'давать', 'давно', 'далее', 'дверь', 'движение', 'двор', 'девушка', 'дело', 'день', 'деньги', 'деревня', 'деревянный', 'десять', 'добро', 'добрый', 'довольно', 'доживать', 'долго', 'должный', 'дом', 'домой', 'дочь', 'древний', 'друг', 'другой', 'дуб', 'думать', 'душа', 'едва', 'ехать', 'жалобный', 'желание', 'желать', 'жениться', 'жених', 'женщина', 'жестокий', 'живой', 'жизнь', 'жить', 'забава', 'заблуждение', 'забывать', 'завтра', 'задумчивость', 'закраснеться', 'закричать', 'заря', 'здешний', 'здравствовать', 'зеленый', 'земля', 'златой', 'знать', 'ибо', 'играть', 'идти', 'имя', 'искать', 'исполняться', 'испугаться', 'история', 'исчезать', 'кабинет', 'казаться', 'какой', 'капля', 'карета', 'карман', 'картина', 'катиться', 'келья', 'клятва', 'колено', 'копейка', 'который', 'красота', 'крест', 'крестьянин', 'крестьянка', 'кровь', 'кроме', 'кто', 'купить', 'ландыш', 'ласка', 'ласковый', 'левый', 'лес', 'лететь', 'летний', 'лето', 'лиза', 'лизин', 'лизина', 'лицо', 'лишний', 'лодка', 'ложиться', 'луг', 'луч', 'любезный', 'любить', 'любовь', 'лютый', 'матушка', 'мать', 'место', 'месяц', 'мечта', 'милый', 'мимо', 'минута', 'многочисленный', 'могила', 'мой', 'молить', 'молиться', 'молния', 'молодой', 'молодость', 'молчать', 'монастырь', 'море', 'москва', 'москва-река', 'мочь', 'мрак', 'мрачный', 'муж', 'мы', 'мысль', 'наглядеться', 'надеяться', 'надлежать', 'надобно', 'называть', 'наступать', 'натура', 'находить', 'наш', 'небесный', 'небо', 'невинность', 'невинный', 'неделя', 'нежели', 'нежный', 'незнакомец', 'некоторый', 'непорочность', 'неприятель', 'несколько', 'никакой', 'никто', 'новый', 'ночь', 'обижать', 'облако', 'обманывать', 'обморок', 'образ', 'обращаться', 'обстоятельство', 'объятие', 'огонь', 'один', 'однако', 'окно', 'окрестности', 'он', 'она', 'они', 'оно', 'опираться', 'описывать', 'опустеть', 'освещать', 'оставаться', 'оставлять', 'останавливать', 'останавливаться', 'отвечать', 'отдавать', 'отец', 'отечество', 'отменно', 'отрада', 'очень', 'падать', 'память', 'пастух', 'первый', 'перемениться', 'переставать', 'песня', 'петь', 'печальный', 'писать', 'питать', 'плакать', 'побежать', 'побледнеть', 'погибать', 'подавать', 'подгорюниваться', 'подле', 'подозревать', 'подымать', 'поехать', 'пойти', 'показываться', 'поклониться', 'покойный', 'покрывать', 'покрываться', 'покупать', 'полагать', 'поле', 'помнить', 'поселянин', 'последний', 'постой', 'потуплять', 'поцеловать', 'поцелуй', 'правый', 'представляться', 'прежде', 'преклонять', 'прекрасный', 'прелестный', 'приводить', 'прижимать', 'принадлежать', 'принуждать', 'природа', 'приходить', 'приятно', 'приятный', 'провожать', 'продавать', 'проливать', 'простой', 'просыпаться', 'проходить', 'проч', 'прощать', 'прощаться', 'пруд', 'птичка', 'пылать', 'пять', 'работа', 'работать', 'радость', 'рассказывать', 'расставаться', 'рвать', 'ребенок', 'река', 'решаться', 'робкий', 'роза', 'розовый', 'роман', 'российский', 'роща', 'рубль', 'рука', 'сам', 'самый', 'свет', 'светиться', 'светлый', 'свидание', 'свирель', 'свободно', 'свое', 'свой', 'свойство', 'сделать', 'сделаться', 'сей', 'сердечный', 'сердце', 'сидеть', 'сие', 'сиять', 'сказать', 'сказывать', 'сквозь', 'скорбь', 'скоро', 'скрываться', 'слабый', 'слеза', 'слезать', 'слово', 'случаться', 'слушать', 'слышать', 'смерть', 'сметь', 'смотреть', 'собственный', 'соглашаться', 'солнце', 'спасать', 'спокойно', 'спокойствие', 'спрашивать', 'стадо', 'становиться', 'стараться', 'старуха', 'старушка', 'старый', 'статься', 'стена', 'сто', 'столь', 'стон', 'стонать', 'сторона', 'стоять', 'страшно', 'страшный', 'судьба', 'схватывать', 'счастие', 'счастливый', 'сын', 'таить', 'такой', 'твой', 'темный', 'тения', 'тихий', 'тихонько', 'томный', 'тот', 'трава', 'трепетать', 'трогать', 'ты', 'убивать', 'уверять', 'увидеть', 'увидеться', 'удерживать', 'удивляться', 'удовольствие', 'узнавать', 'улица', 'улыбка', 'уметь', 'умирать', 'унылый', 'упасть', 'услышать', 'утешение', 'утро', 'хижина', 'хлеб', 'ходить', 'холм', 'хороший', 'хотеть', 'хотеться', 'хотя', 'худо', 'худой', 'царь', 'цветок', 'целовать', 'час', 'часто', 'человек', 'чистый', 'читатель', 'чувствительный', 'чувство', 'чувствовать', 'чулок', 'шестой', 'шум', 'шуметь', 'щадить', 'щека', 'эраст', 'эрастов', 'это', 'я']\n"
     ]
    }
   ],
   "source": [
    "print(sorted([w for w in model_liza.wv.vocab]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И чему же мы ее научили? Попробуем оценить модель вручную, порешав примеры. Несколько дано ниже, попробуйте придумать свои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('слеза', 0.200484037399292)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.most_similar(positive=[\"смерть\", \"любовь\"], negative=[\"печальный\"], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('слеза', 0.2169419825077057),\n",
       " ('жизнь', 0.18847499787807465),\n",
       " ('сей', 0.1782345473766327)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.most_similar(\"любовь\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14720827"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.similarity(\"лиза\", \"эраст\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'скорбь'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.doesnt_match(\"скорбь грусть слеза улыбка\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['свой',\n",
       " 'сей',\n",
       " 'сердце',\n",
       " 'мой',\n",
       " 'день',\n",
       " 'говорить',\n",
       " 'часто',\n",
       " 'жить',\n",
       " 'слеза',\n",
       " 'цветок',\n",
       " 'время',\n",
       " 'добрый',\n",
       " 'взять',\n",
       " 'чистый',\n",
       " 'любовь',\n",
       " 'место',\n",
       " 'прежде',\n",
       " 'взглядывать',\n",
       " 'казаться',\n",
       " 'должный',\n",
       " 'бояться',\n",
       " 'роща',\n",
       " 'трава',\n",
       " 'птичка',\n",
       " 'таить',\n",
       " 'щека',\n",
       " 'некоторый',\n",
       " 'правый',\n",
       " 'весна',\n",
       " 'чулок',\n",
       " 'эрастов',\n",
       " 'здешний']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liza.wv.words_closer_than(\"лиза\", \"эраст\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как использовать готовую модель\n",
    "\n",
    "#### RusVectōrēs\n",
    "\n",
    "На сайте RusVectōrēs (https://rusvectores.org/ru/) собраны предобученные на различных данных модели для русского языка, а также можно поискать наиболее близкие слова к заданному, посчитать семантическую близость нескольких слов и порешать примеры с помощью «калькулятором семантической близости».\n",
    "\n",
    "Для других языков также можно найти предобученные модели — например, модели [fastText](https://fasttext.cc/docs/en/english-vectors.html) и [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "Ещё давайте посмотрим на векторные романы https://nevmenandr.github.io/novel2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Работа с моделью\n",
    "\n",
    "Модели word2vec бывают разных форматов:\n",
    "\n",
    "+ .vec.gz — обычный файл\n",
    "+ .bin.gz — бинарник\n",
    "\n",
    "Загружаются они с помощью одного и того же гласса `KeyedVectors`, меняется только параметр `binary` у функции `load_word2vec_format`.\n",
    "\n",
    "Если же эмбеддинги обучены не с помощью word2vec, то для загрузки нужно использовать функцию `load`. Т.е. для загрузки предобученных эмбеддингов `glove`, `fasttext`, `bpe` и любых других нужна именно она.\n",
    "\n",
    "Скачаем с RusVectōrēs модель для русского языка, обученную на НКРЯ образца 2015 г."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
       " <http.client.HTTPMessage at 0x7f35d4f85da0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 14:02:21,284 : INFO : loading projection weights from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n",
      "2019-10-17 14:02:29,342 : INFO : loaded (281776, 300) matrix from ruscorpora_mystem_cbow_300_2_2015.bin.gz\n"
     ]
    }
   ],
   "source": [
    "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
    "\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['день_S', 'ночь_S', 'человек_S', 'семантика_S', 'студент_S', 'биткоин_S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частеречные тэги нужны, поскольку это специфика скачанной модели - она была натренирована на словах, аннотированных их частями речи (и лемматизированных). NB! В названиях моделей на `rusvectores` указано, какой тегсет они используют (mystem, upos и т.д.)\n",
    "\n",
    "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 14:02:45,061 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "день_S\n",
      "[-0.02580778  0.00970898  0.01941961 -0.02332282  0.02017624  0.07275085\n",
      " -0.01444375  0.03316632  0.01242602  0.02833412]\n",
      "неделя_S 0.7165195941925049\n",
      "месяц_S 0.631048858165741\n",
      "вечер_S 0.5828739404678345\n",
      "утро_S 0.5676207542419434\n",
      "час_S 0.5605547428131104\n",
      "минута_S 0.5297019481658936\n",
      "гекатомбеон_S 0.4897990822792053\n",
      "денек_S 0.48224714398384094\n",
      "полчаса_S 0.48217129707336426\n",
      "ночь_S 0.478074848651886\n",
      "\n",
      "\n",
      "ночь_S\n",
      "[-0.00688948  0.00408364  0.06975466 -0.00959525  0.0194835   0.04057068\n",
      " -0.00994112  0.06064967 -0.00522624  0.00520327]\n",
      "вечер_S 0.6946247816085815\n",
      "утро_S 0.57301926612854\n",
      "ноченька_S 0.5582467317581177\n",
      "рассвет_S 0.5553582906723022\n",
      "ночка_S 0.5351512432098389\n",
      "полдень_S 0.5334426164627075\n",
      "полночь_S 0.478694349527359\n",
      "день_S 0.4780748784542084\n",
      "сумерки_S 0.4390218257904053\n",
      "фундерфун_S 0.4340824782848358\n",
      "\n",
      "\n",
      "человек_S\n",
      "[ 0.02013756 -0.02670703 -0.02039861 -0.05477146  0.00086402 -0.01636335\n",
      "  0.04240306 -0.00025525 -0.14045681  0.04785006]\n",
      "женщина_S 0.5979775190353394\n",
      "парень_S 0.4991787374019623\n",
      "мужчина_S 0.4767409563064575\n",
      "мужик_S 0.47384002804756165\n",
      "россиянин_S 0.47190436720848083\n",
      "народ_S 0.4654741883277893\n",
      "согражданин_S 0.45378512144088745\n",
      "горожанин_S 0.44368088245391846\n",
      "девушка_S 0.44314485788345337\n",
      "иностранец_S 0.43849867582321167\n",
      "\n",
      "\n",
      "семантика_S\n",
      "[-0.03066749  0.0053851   0.1110732   0.0152335   0.00440643  0.00384104\n",
      "  0.00096944 -0.03538784 -0.00079585  0.03220548]\n",
      "семантический_A 0.5334584712982178\n",
      "понятие_S 0.5030269622802734\n",
      "сочетаемость_S 0.4817051291465759\n",
      "актант_S 0.47596412897109985\n",
      "хронотоп_S 0.46330299973487854\n",
      "метафора_S 0.46158894896507263\n",
      "мышление_S 0.4610119163990021\n",
      "парадигма_S 0.45796656608581543\n",
      "лексема_S 0.45688074827194214\n",
      "смысловой_A 0.4543077349662781\n",
      "\n",
      "\n",
      "студент_S\n",
      "[ 0.02558023  0.0529849  -0.07036145  0.00279281 -0.09874777 -0.01620521\n",
      " -0.03918766  0.0326411   0.09191283  0.03495219]\n",
      "преподаватель_S 0.6958175897598267\n",
      "аспирант_S 0.6589953899383545\n",
      "выпускник_S 0.6523089408874512\n",
      "студентка_S 0.6321653127670288\n",
      "профессор_S 0.6080018281936646\n",
      "курсистка_S 0.5818493366241455\n",
      "юрфак_S 0.580669105052948\n",
      "первокурсник_S 0.5805511474609375\n",
      "семинарист_S 0.5773230791091919\n",
      "гимназист_S 0.5747809410095215\n",
      "\n",
      "\n",
      "Увы, слова \"биткоин_S\" нет в модели!\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    # есть ли слово в модели? \n",
    "    if word in model:\n",
    "        print(word)\n",
    "        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n",
    "        print(model[word][:10])\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for i in model.most_similar(positive=[word], topn=10):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(i[0], i[1])\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print('Увы, слова \"%s\" нет в модели!' % word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим косинусную близость пары слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23895611\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('человек_S', 'обезьяна_S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что получится, если вычесть из пиццы Италию и прибавить Сибирь?\n",
    "\n",
    "+ positive — вектора, которые мы складываем\n",
    "+ negative — вектора, которые вычитаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пельмень_S\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['пицца_S', 'сибирь_S'], negative=['италия_S'])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найди лишнее!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 14:02:56,952 : WARNING : vectors for words {'ничто_S'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мир_S\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match('мир_S жизнь_S бытие_S ничто_S'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3734\tбыт_S\n",
      "0.3261\tжисть_S\n",
      "0.2944\tсуществование_S\n",
      "0.281\tобстановка_S\n",
      "0.2615\tмахаль_S\n",
      "0.2572\tжизень_S\n",
      "0.2564\tуклад_S\n",
      "0.2556\tскарб_S\n",
      "0.2515\tжитие_S\n",
      "0.2505\tпередряга_S\n"
     ]
    }
   ],
   "source": [
    "for word, score in model.most_similar(positive=['жизнь_S'], negative=['любовь_S']):\n",
    "    print(f'{score:.4}\\t{word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка\n",
    "\n",
    "Это, конечно, хорошо, но как понять, какая модель лучше? Или вот, например, я сделал свою модель, а как понять, насколько она хорошая?\n",
    "\n",
    "Для этого существуют специальные датасеты для оценки качества дистрибутивных моделей. Основных два: один измеряет точность решения задач на аналогии (про Россию и пельмени), а второй используется для оценки коэффициента семантической близости.\n",
    "\n",
    "#### Word Similarity\n",
    "\n",
    "Этот метод заключается в том, чтобы оценить, насколько представления о семантической близости слов в модели соотносятся с \\\"представлениями\\\" людей.\n",
    "\n",
    "| слово 1    | слово 2    | близость |\n",
    "|------------|------------|----------|\n",
    "| кошка      | собака     | 0.7      | \n",
    "| чашка      | кружка     | 0.9      | \n",
    "\n",
    "Для каждой пары слов из заранее заданного датасета мы можем посчитать косинусное расстояние, и получить список таких значений близости. При этом у нас уже есть список значений близостей, сделанный людьми. Мы можем сравнить эти два списка и понять, насколько они похожи (например, посчитав корреляцию). Эта мера схожести должна говорить о том, насколько модель хорошо моделирует расстояния о слова.\n",
    "\n",
    "#### Аналогии\n",
    "\n",
    "Другая популярная задача для \"внутренней\" оценки называется задачей поиска аналогий. Как мы уже разбирали выше, с помощью простых арифметических операций мы можем модифицировать значение слова. Если заранее собрать набор слов-модификаторов, а также слов, которые мы хотим получить в результаты модификации, то на основе подсчёта количества \"попаданий\" в желаемое слово мы можем оценить, насколько хорошо работает модель.\n",
    "\n",
    "В качестве слов-модификатор мы можем использовать семантические аналогии. Скажем, если у нас есть некоторое отношение \"страна-столица\", то для оценки модели мы можем использовать пары наподобие \"Россия-Москва\", \"Норвегия-Осло\", и т.д. Датасет будет выглядеть следующм образом:\n",
    "\n",
    "| слово 1    | слово 2    | отношение     | \n",
    "|------------|------------|---------------|\n",
    "| Россия     | Москва     | страна-столица| \n",
    "| Норвегия   | Осло       | страна-столица|\n",
    "\n",
    "Рассматривая случайные две пары из этого набора, мы хотим, имея триплет (Россия, Москва, Норвегия) хотим получить слово \"Осло\", т.е. найти такое слово, которое будет находиться в том же отношении со словом \"Норвегия\", как \"Россия\" находится с Москвой.\n",
    "\n",
    "Датасеты для русского языка можно скачать на странице с моделями на RusVectores. Посчитаем качество нашей модели НКРЯ на датасете про аналогии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-17 14:06:20,510 : INFO : capital-common-countries: 19.0% (58/306)\n",
      "2019-10-17 14:06:24,401 : INFO : capital-world: 10.1% (52/515)\n",
      "2019-10-17 14:06:25,328 : INFO : currency: 4.6% (6/130)\n",
      "2019-10-17 14:06:27,458 : INFO : family: 71.2% (218/306)\n",
      "2019-10-17 14:06:33,288 : INFO : gram1-Aective-to-adverb: 18.7% (152/812)\n",
      "2019-10-17 14:06:35,937 : INFO : gram2-opposite: 32.1% (122/380)\n",
      "2019-10-17 14:06:42,301 : INFO : gram6-nationality-Aective: 32.3% (293/907)\n",
      "2019-10-17 14:06:42,303 : INFO : total: 26.8% (901/3356)\n"
     ]
    }
   ],
   "source": [
    "res = model.accuracy('ru_analogy_tagged.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "МАЛЬЧИК_S\tДЕВОЧКА_S\tДЕД_S\tБАБКА_S\n",
      "МАЛЬЧИК_S\tДЕВОЧКА_S\tКОРОЛЬ_S\tКОРОЛЕВА_S\n",
      "МАЛЬЧИК_S\tДЕВОЧКА_S\tПРИНЦ_S\tПРИНЦЕССА_S\n",
      "МАЛЬЧИК_S\tДЕВОЧКА_S\tОТЧИМ_S\tМАЧЕХА_S\n",
      "МАЛЬЧИК_S\tДЕВОЧКА_S\tПАСЫНОК_S\tПАДЧЕРИЦА_S\n",
      "БРАТ_S\tСЕСТРА_S\tДЕД_S\tБАБКА_S\n",
      "БРАТ_S\tСЕСТРА_S\tОТЧИМ_S\tМАЧЕХА_S\n",
      "БРАТ_S\tСЕСТРА_S\tПАСЫНОК_S\tПАДЧЕРИЦА_S\n",
      "ПАПА_S\tМАМА_S\tДЕД_S\tБАБКА_S\n",
      "ПАПА_S\tМАМА_S\tОТЧИМ_S\tМАЧЕХА_S\n"
     ]
    }
   ],
   "source": [
    "for row in res[4]['incorrect'][:10]:\n",
    "    print('\\t'.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализация**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использовать разные методы того, как преобразовать векторы так, чтобы можно было их поместить на двумерное пространство, например, с помощью PCA. В зависимости от того, относительно какого набора слов вы пытаетесь найти оптимально отображение на двумерное пространство, у вас могут получаться разные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['кошка_S', 'собака_S', 'корова_S', 'коза_S', 'бык_S']\n",
    "X = model[words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На списке конкретных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
    "plt.title('Words')\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На все словах в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(model[list(model.vocab)])\n",
    "coords = pca.transform(model[words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(coords[:, 0], coords[:, 1], color='red')\n",
    "plt.title('Words')\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(coords[i, 0], coords[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "\n",
    "+ Возьмите небольшой кусочек текста или стихотворение.\n",
    "+ Замените все неслужебные слова в нём на их ближайших соседей из нашей модели.\n",
    "+ Прокомментируйте результат.\n",
    "\n",
    "#### Задание 2\n",
    "\n",
    "+ Возьмите интересный Вам текст.\n",
    "+ Лемматизируйте текст, отчистите от пунктуации и служебной информации и обучите на нем модель word2vec (поэкспериментируйте с размером окна, с длиной вектора). \n",
    "+ Найдите по 5 ближайших слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы). Учтите, что слова может не быть в модели!\n",
    "+ Найдите по 5 \"далёких\" слов к нескольким интересующим Вас словам. Обязательно попробуйте взять слова различной частеречной принадлежности, различных семантических классов (абстрактные слова, экспрессивы).\n",
    "+ Прокомментируйте результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
